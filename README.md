Awesome Data Engineering
==========================
A curated list of data engineering tools for software developers

List of content

- [Data Warehouses](#data-warehouses)
- [Ingestion](#data-ingestion)
- [File Format](#file-format)
- [Kafka](#kafka)

# Data Warehouses
* [Hive] (http://hive.apache.org)

# Data Ingestion
* [Kafka] (http://kafka.apache.org/)
* [AWS Kinesis] (http://aws.amazon.com/kinesis/)
* [RabbitMQ](http://rabbitmq.com)
* [FluentD](http://www.fluentd.org)
* [Apache Scoop](https://sqoop.apache.org)

# File Format
* [Apache Avro](https://avro.apache.org) Apache Avroâ„¢ is a data serialization system
* [Apache Parquet](https://parquet.apache.org) Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.
* [Apache Thrift](https://thrift.apache.org) The Apache Thrift software framework, for scalable cross-language services development
* [ProtoBuf](https://github.com/google/protobuf) Protocol Buffers - Google's data interchange format
* [SequenceFile](http://wiki.apache.org/hadoop/SequenceFile) SequenceFile is a flat file consisting of binary key/value pairs. It is extensively used in MapReduce as input/output formats

# Kafka
* [Camus](https://github.com/linkedin/camus) LinkedIn's Kafka to HDFS pipeline.
* [BottledWater](https://github.com/confluentinc/bottledwater-pg) Change data capture from PostgreSQL into Kafka
* [kafkat](https://github.com/airbnb/kafkat) Simplified command-line administration for Kafka brokers


Cheers to [The Data Engineering Ecosystem: An Interactive Map](http://insightdataengineering.com/blog/pipeline_map.html)

Inspired by the [awesome](https://github.com/sindresorhus/awesome) list. Created by [Insight Data Engineering](http://insightdataengineering.com) fellows.
